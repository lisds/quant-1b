---
jupyter:
  jupytext:
    cell_metadata_json: true
    split_at_heading: true
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.4
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- #region {"editable": true, "slideshow": {"slide_type": ""}} -->
# A cure for cancer?
<!-- #endregion -->

## Preliminaries

```{python}
# Run this cell to start.
import numpy as np

# A Numpy random number generator.
rng = np.random.default_rng()

# Load the OKpy test library and tests.
from client.api.notebook import Notebook
ok = Notebook('lymphoma.ok')
```

The tests in this notebook do not test if you have the right answer, but only
if you have the *right sort* of answer.  *Be careful* -- the tests could pass, but your answer could still be wrong.

## Is there a cure?

At the time of writing, you could find the following on the [Wikipedia page for
Burkitt's
Lymphoma](https://en.wikipedia.org/wiki/Burkitt%27s_lymphoma#Prognosis).

> The overall cure rate for Burkitt's lymphoma in developed countries is
> about 90%, but worse in low-income countries. Burkitt's lymphoma is
> uncommon in adults, where it has a worse prognosis (Molyneux et al 2012).
>
> In 2006, treatment with dose-adjusted EPOCH with Rituximab showed
> promising initial results in a small series of patients (n=19), with
> a 100% response rate, and 100% overall survival and progression-free
> survival at 28 months (median follow-up) ([version of] Dunleavy et al 2006).

* Molyneux *et al* (2012). Burkitt's Lymphoma.  The Lancet, 379(9822),
  1234-1244.
* Dunleavy *et al* (2006). Novel Treatment of Burkitt Lymphoma with
  Dose-Adjusted EPOCH-Rituximab: Preliminary Results Showing Excellent Outcome.
  Blood, 108(11), 2736â€“2736.

How likely is it that the Dunleavy 2006 study results, or better, could have
come about by chance?

You can use the tools you already know like this:

* Your ideal (null) model is that the EPOCH study was, in fact, no more
  effective than any other standard therapy.
* You are going to simulate 10000 trials, using this model.
* In each trial, you will make 19 simulated patients, each with a 90%
  chance of being cured.  Then count how many of the 19 patients were cured.
* At the end of your simulation, you should have 10000 counts of the number of
  simulated patients, out of 19, who were cured.  Store these counts in
  a variable `counts`.

To start, here's a cell where you can work out the code to simulate one trial (of 19 patients):

```{python}
were_cured = ...
number_cured = ...
```

Here's the cell for you to run the trial, and store the result, 10000 times.

```{python editable=TRUE, slideshow={'slide_type': ''}}
#- Simulate 10000 trials of 19 patients
n_iters = 10000

counts = ...
     ...
     ...

# Show the first five counts

```

```{python}
# Test you are on the right track.
_ = ok.grade('q_01_counts')
```

Calculate the *proportion* `p_100` of `counts` that correspond to 100% response
rate (19 out of 19):

```{python}
p_100 = ...
# Show the value
p_100
```

```{python}
# Test you are on the right track.
_ = ok.grade('q_02_p_100')
```

## The rush to publish

One big problem in medical research, as in other research, is the *file-drawer
effect*, also called [publication
bias](https://en.wikipedia.org/wiki/Publication_bias).

The problem is that there may be multiple labs testing the same treatment.
Labs that do not find a surprising result, will probably not publish a paper.  Labs that do, probably will publish a paper.

Imagine there were four labs all testing the same treatment as Dunleavy *et
al*.  They also tested 19 patients, and looked at the number of patients
who are progression-free after about 28 months follow-up - like Dunleavy. Again
imagine, in our ideal model of the world, the treatment is, in fact, no more
effective than average.

Now imagine that each of the four labs will publish a paper if they get 19 of 19 progression-free survival rate, and will not publish otherwise.

In this ideal world, what is the chance that at least one lab will publish a paper?

Here is a sketch of a simulation of one trial in that world:

```{python tags=c("raises-exception")}
# This code is rather ugly, and needs editing to work correctly.
lab_counts = np.zeros(4)
lab_counts[0] = ... # Simulate a count of patients cured in first lab.
lab_counts[1] = ... # Simulate a count of patients cured in second lab.
lab_counts[2] = ... # Simulate a count of patients cured in third lab.
lab_counts[3] = ... # Simulate a count of patients cured for fourth lab.
n_publications = np.count_nonzero(lab_counts == 19)
```

Now do a simulation of 10000 trials like this.  Count the number of publications for each trial.  Store the number of publications for each trial in an array `publications`.


```{python editable=TRUE, slideshow={'slide_type': ''}}
#- Simulate 10000 trials of four labs, each studying 19 patients.
n_iters = 10000

publications = ...
    ...
    ...
# Show the first five publication counts

```

```{python}
# Test you are on the right track.
_ = ok.grade('q_04_publications')
```

In this world, where each trial has four labs, each testing the same thing,
what proportion of trials give at least one publication?

```{python}
p_at_least_one = ...

# Show the value

```

```{python}
# Test you are on the right track.
_ = ok.grade('q_05_p_at_least_one')
```

With the evidence you have here, in the Wikipedia page, and from any extra
reading you would like to do, how likely is it that the treatment that Dunleavy
*et al* used is really more effective than other standard treatments for
Burkitt's lymphoma?  If you had Burkitt's lymphoma, would you insist on this
treatment?  Give your answer, with arguments, in the space below.

<!-- #region {"manual_grade": true, "manual_problem_id": "dunleavy_plausible"} -->
*Write your answer here, replacing this text.*
<!-- #endregion -->

## Done

You're finished with the assignment!  Be sure to...

- **run all the tests** (the next cell has a shortcut for that),
- **Save and Checkpoint** from the "File" menu.
- Finally, **restart** the kernel for this notebook, and **run all the cells**,
  to check that the notebook still works without errors.  Use the
  "Kernel" menu, and choose "Restart and Run All".  If you find any
  problems, go back and fix them, save the notebook, and restart / run
  all again, before submitting.

```{python editable=TRUE, slideshow={'slide_type': ''}}
# For your convenience, you can run this cell to run all the tests at once!
import os
_ = [ok.grade(q[:-3]) for q in os.listdir("tests") if q.startswith('q')]
```
